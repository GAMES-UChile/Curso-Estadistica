%!TEX root = ../notas_de_clase.tex


\chapter{Introducción}

En este capítulo se motivará el estudio de la estadística, dando a conocer su campo de acción, junto con su relación con otras disciplinas de la matemática teórica y aplicada. 

\section{Motivación}

Consideremos el siguiente escenario. Una moneda es lanzada al aire $99$ veces, y en todas ellas observamos una \emph{cara} (y ningún  \emph{sello}). En esta inusual situación, le preguntamos a una colega matemática cuál es la probabilidad de que el siguiente lanzamiento resulte sello. Ella no duda en responder "$\frac{1}{2}$".  Implícitamente, nuestra colega ha asumido que la moneda no está \emph{cargada}, es decir, que la probabilidad de observar cara o sello es la misma y consecuentemente la probabilidad de obtener el resultado de las 99 caras tiene probabilidad $(1/2)
^{99}$, al igual que cualquiera de los otros $2^{99}$ posibles resultados (secuencias) de este experimento. El supuesto de que la moneda no está cargada puede venir del hecho que ella no tiene evidencia sobre la forma y/o composición de la moneda que le permitan confiar que ésta está cargada, entonces, ante esta falta de información, nuestra colega asume igual probabilidad de obtener cara o sello.

En este curso, estudiaremos una vía alternativa para evaluar si la moneda está cargada no, prescindiendo del conocimiento los aspectos físicos de la moneda. De hecho, notemos que el obtener 99 caras seguidas sugiere fuertemente que la moneda sí está  cargada: si asumimos que la moneda no está cargada, en 99 lanzamientos existe una probabilidad de 
\[1-(1/2)
^{99} = 0.9999999999999999999999999999984222782\ldots\]
de ver al menos un sello. Con lo que nos gustaría decir que la moneda está cargada como \emph{por contradicción}. En la misma línea, ante el resultado mencionado anteriormente, podemos decir que la probabilidad de que la moneda \textbf{esté cargada} es mayor que la probabilidad de que no lo esté. Este ejemplo del lanzamiento de una moneda desconocida es una ilustración para escenarios generales donde desconocemos las propiedades físicas pero tenemos \emph{evidencia empírica}, \emph{datos}, \emph{realizaciones} (en caso que consideramos que estos fenómenos son expresiones de una variable aleatoria). En este escenario, aflora naturalmente la siguiente pregunta: ¿Será posible usar datos para obtener mejores predicciones o decisiones?

Pareciese entonces que la estadística tiene que ver con las probabilidades, pues ambas hablan de \emph{realizaciones} y de \emph{probabilidad de ocurrencia}. Sin embargo, es precisamente al considerar el \emph{uso de datos} para dilucidar las propiedades intrínsecas de un objeto o fenómeno general, lo que nos lleva a entender la diferencia entre las probabilidades y la estadística. La primera se dedica al estudio del comportamiento de los fenómenos naturales asumiendo que conocemos sus propiedades, tal como el caso descrito en el Ejemplo \ref{ex:prob_proba}.
\begin{example}[enfoque de las probabilidades]
\label{ex:prob_proba}
Asuma que tiene un dado de 6 caras \textbf{no cargado}. ¿Cuál es la probabilidad de que, dentro de $2N$ lanzamientos, obtenga más de $N$ resultados pares?
\end{example}

La estadística, por el contrario, se dedica a entender las propiedades inherentes de los objetos/fenómenos (que usualmente son asumidas en el estudio de Probabilidades) desde sus realizaciones como en el ejemplo \ref{ex:prob_esta}.
\begin{example} [enfoque de la estadística]
\label{ex:prob_esta}
Ante la observación de una secuencia de $N$ lanzamientos de un dado, cuya media y desviación estándar (muestral) están dadas por $\bar{x}$ y $\bar{s}$, ¿cuál es la probabilidad de que el dado esté cargado?
\end{example}

La diferencia entre ambas disciplinas es muy sutil para el no experto, pero informalmente podemos postular que el objetivo de la inferencia estadística está en la \emph{dirección opuesta} al de las probabilidades: mientras que la última asume parámetros para predecir resultados, la primera usa resultados para estimar parámetros. Otra forma coloquial de ilustrar esta diferencia es decir que en probabilidades estudiamos las consecuencias de un mundo ideal, mientras que en estadística verificamos hasta qué punto nuestro mundo es ideal. Un diagrama de la relación entre probabilidades y estadística se ilustra a continuación. 

\begin{table}[H]
\centering
\begin{tabular}{ccc}
$\rightarrow\rightarrow\rightarrow$ & Probabilidades & $\rightarrow\rightarrow\rightarrow$ \\
general       &                & particular    \\
población     &                & muestra       \\
modelo        &                & datos         \\
$\leftarrow\leftarrow\leftarrow$  & Estadística    & $\leftarrow\leftarrow\leftarrow$ 
\end{tabular}
\end{table}

Por esta razón, hay quienes dicen que la inferencia estadística es una \textbf{probabilidad inversa}.

Si bien hay diferencias claras que pueden ser identificadas en ambos enfoques, los recursos de las probabilidades y de la estadística suelen usarse en conjunto para problemas como el enunciado en el Ejemplo \ref{ex:prob_probaesta}. En este caso, lo natural es en primer lugar usar los recursos de la estadística para identificar las propiedades del dado. Luego, podemos usar probabilidades para predecir el comportamiento del dado en el futuro. En este curso nos dedicaremos también a preguntas de este tipo, en donde realizamos ambos pasos de forma simultánea. 

\begin{example}[probabilidades y estadística]
\label{ex:prob_probaesta}
Considere que de $N$ lanzamientos de un dado, el cuál no sabemos si está cargado o no, se han obtenido cantidades $s_1,s_2,s_3,s_4,s_5,s_6$ de 1's, 2's, 3's, 4's, 5's y 6's respectivamente. ¿Cuál es la probabilidad de obtener un 4 en los siguientes dos lanzamientos?
\end{example}

Lo anterior entonces nos deja en posición para bosquejar lo que puede ser una definición de la Estadística. 

\section{¿Qué es la estadística?}

Si bien hay un sinnúmero de definiciones, en base a lo postulado por David Spiegelhalter, consideraremos que la estadística es: 
\begin{center}
\it 
    Un conjunto de principios y procedimientos para obtener y procesar evidencia cuantitativa para apoyar la toma de decisiones, hacer juicios, entender fenómenos naturales y hacer predicciones
\end{center}

Con lo que la Estadística no es únicamente \emph{análisis de datos}, sino que también considera: diseño de experimentos, exploración de datos de forma gráfica, interpretación informal de datos, análisis formal estadístico, comunicación de resultados de forma clara, modelación y presentación de incertidumbre. 

Desde un punto de vista más conceptual, podemos entender la estadística como una forma de razonamiento inductivo. Recordemos que una desventaja del razonamiento/lógica deductivo/a es que de alguna forma todas las consecuencias están incluidas en las premisas, con lo que, \emph{uno no aprende nada}. El razonamiento inductivo por el contrario, nos permite aprender de observaciones de nuestro entorno, de forma empírica, a costa de no tener seguridad de lo que aprendemos. En este sentido, podemos entender las probabilidades como un ejemplo de lógica inductiva y la estadística como deductiva, donde mediante la modelación de la incertidumbre, la estadística representa un entorno para estudiar el problema de inducción: generalizar en base a observaciones. Podemos adelantar que no es posible aprender solo de observaciones pero sí disminuir nuestra incertidumbre, en particular, las observaciones solo nos permiten descartar hechos con seguridad, mas nunca confirmarlos, como se ilustra en la siguiente cita. 

\begin{displayquote}[Bertrand Russell Los problemas de la filosofía]   
Los animales domésticos esperan su alimento
cuando ven la persona que habitualmente se lo da. Sabemos que todas estas
expectativas, más bien burdas, de uniformidad, están sujetas a error. El hombre que
daba de comer todos los días al pollo, a la postre le tuerce el cuello, demostrando con
ello que hubiesen sido útiles al pollo opiniones más afinadas sobre la uniformidad de la naturaleza.
\end{displayquote}

Finalmente, hemos mencionado varias veces el concepto \emph{aprender} durante esta sección. Esto es porque la Estadística ha sido instrumental en el desarrollo del Aprendizaje de Máquinas (AM),  una componente de la Inteligencia Artificial que permite construir sistemas inteligentes de forma autónoma (sin la necesidad de que que éstos sean explícitamente programados). En su objetivo, el AM permite que estas máquinas \emph{aprendan} del mundo mendiante observaciones donde los modelos estadísticos y el uso de datos para su ajuste es fundamental, desde ahí el rol de la estadística en el AM y el uso del término \emph{aprender} (modelos) como una alternativa al término más clásico \emph{ajustar}. En el mismo contexto, la estadística ha jugado un rol preponderante en disciplinas como minería de datos, Big Data, ciencia/análisis de datos y tantos otros. 

\section{Enfoques frecuentista y Bayesiano}

La estadística moderna considera principalmente dos enfoques distintos para abordar el problema de inferencia, ambos enfoques son complementarios. Su diferencia fundamental reside en el significado que cada uno le da a la probabilidad.

El primero de ellos es el enfoque clásico conocido como \textbf{frecuentista}. En este enfoque, la probabilidad adquiere el significado al que estamos acostumbrados: Casos favorables divido en casos totales. Teniendo esto en cuenta, el enfoque frecuentista define la probabilidad como una \emph{frecuencia límite}, es decir, la probabilidad de un evento es la razón entre las veces que ocurre y el total de las veces, cuando éste último tiene a infinito. Dos características directas de esta definición son que i) las probabilidad de ocurrencia de un hecho depende de la naturaleza de éste, y ii) no tiene sentido definir probabilidades de eventos que son irrepetibles.

Las herramientas frecuentistas fueron desarrolladas hasta inicios del siglo pasado, como respuesta al tratamiento informal de las probabilidades existente hasta ese entonces, y su introducción fue muy exitosa en el sentido de equipar a las probabilidades con tratamiento matemático riguroso. Sin embargo, el enfoque frecuentitsta tiene limitantes, además de los dos puntos mencionados arriba, un problema relacionado con este enfoque es que no brinda un tratamiento natural para el problema de inferencia que permita incluir incertidumbre o sesgos del observador, como por ejemplo el  \emph{conocimiento experto}.

El segundo enfoque es el \textbf{Bayesiano}, el que si bien data de antes de la introducción del tratamiento formal del frecuentismo, recientemente ha sido retomado y complementado con los avances teóricos frecuentistas. El paradigma bayesiano postula que la probabilidad es una medida de incertidumbre (y no de frecuencia límite) o grado de creencia en la ocurrencia de un evento. Consecuentemente, este enfoque es subjetivo, pues la incertidumbre está en los ojos del observador, y además es perfectamente correcto definir probabilidades sobre hechos que no son repetibles.

En resumen, el enfoque clásico o \emph{frecuentista}, asume lo siguiente: 
\begin{itemize}
	\item El concepto de probabilidad está relacionado con frecuencias límites, es decir, la probabilidad de un evento es la razón de veces que este ocurre versus las veces que no ocurre (usualmente referido como \emph{casos favorables dividido por casos totales}). En este sentido, la probabilidad es una propiedad del mundo real. 
	\item Los parámetros son constantes (fijos) y desconocidos, es decir, no existe \emph{aleatoriedad} relacionada a los parámetros, por ende no podemos construir enunciados probabilísticos con respecto a ellos
	\item El procedimiento estadístico debe comportarse bien en el largo plazo, un ejemplo de esto es que un ($1-\alpha$)-intervalo de confianza debe capturar (asintóticamente) el parámetro una fracción $1-\alpha$ de las veces luego de infinitos experimentos. 
\end{itemize}

Por otro lado, el \textbf{enfoque bayesiano} se caracteriza por lo siguiente: 

\begin{itemize}
 	\item La probabilidad es subjetiva y denota un grado de \emph{creencia}, es decir, la aleatoriedad de un evento no solo es intrínseca de éste sino también de nuestra observación
 	\item Lo anterior permite considerar aleatoriedad en los parámetros, pues el hecho de que éstos sean fijos no quiere decir que los conozcamos. 
 	\item Podemos considerar los parámetros como VAs y, consecuentemente, calcular su distribución de probabilidad. Inferencias puntuales o la incidencia de este parámetro en otras VAs está completamente determinada por su distribución.
 \end{itemize}
 Existen ventajas y desventajas para ambos enfoques, lo cual hace que ambos sean considerados en distintas aplicaciones. Si bien el enfoque bayesiano es muy antiguo, la estadística clásica ha privilegiado un punto de vista frecuentista, mientras que disciplinas como minería de datos y aprendizaje de máquinas se inclinan por el enfoque bayesiano. De todas formas actualmente ambos métodos se consideran en base a sus propios méritos. 
 
